{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ffb73904",
   "metadata": {},
   "source": [
    "Reese Final Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd053a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "#External libraries\n",
    "# This cell imports libraries that this code uses\n",
    "\n",
    "import numpy as np                   # functions for data analysis \n",
    "import pandas as pd                  # functions for data frames\n",
    "from matplotlib import pyplot as plt\n",
    "import datetime \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b1a7eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Constants\n",
    "\n",
    "startdate = datetime.datetime(1969, 1, 1)\n",
    "enddate = datetime.datetime(2020, 12, 31)\n",
    "\n",
    "headerlist = ['Date Time', 'Water Level', 'I', 'L']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede15df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Ingesting, organizing, and filling missing water level data\n",
    "\n",
    "waterlevelfiles =  ['olc68to77.csv', 'olc78to87.csv', 'olc88to97.csv', 'olc98to07.csv',\n",
    "               'olc08to17.csv', 'olc18to20.csv', 'Cape68to77.csv', 'Cape78to87.csv',\n",
    "               'Cape88to97.csv', 'Cape98to07.csv', 'Cape08to17.csv', 'Cape18to20.csv',\n",
    "               'Oz68to77.csv', 'Oz78to87.csv', 'Oz88to97.csv', 'Oz98to07.csv', \n",
    "               'Oz08to17.csv', 'Oz18to20.csv', 'Roch68to77.csv', 'Roch78to87.csv', \n",
    "               'Roch88to97.csv', 'Roch98to07.csv', 'Roch08to17.csv', 'Roch18to20.csv', \n",
    "               ]\n",
    "\n",
    "dscgfiles = ['niagdscg.csv', 'lawdscg.csv', 'genndscg.csv', 'blkdscg.csv', 'ozdscg.csv']\n",
    "\n",
    "prcpfile = ['ozprcp.csv', 'rochprcp.csv', 'wtprcp.csv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3318135a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#%% Importing Water Level Data\n",
    "\n",
    "olcdflvl0 = pd.read_csv(waterlevelfiles[0], delimiter=',', comment='#', header=0, \n",
    "                 parse_dates=['Date Time'], index_col= 'Date Time', na_values = \n",
    "                  [2.0181e+11, 2.01902e+11, -9999, 9999, 'NaN', 'Ice', 'Eqp'])\n",
    "olcdflvl0.rename(columns=lambda x: x.strip(), inplace=True) #stripping spaces out of names\n",
    "\n",
    "olcdflvl1 = pd.read_csv(waterlevelfiles[1], delimiter=',', comment='#', header=0, \n",
    "                 parse_dates=['Date Time'], index_col= 'Date Time', na_values = \n",
    "                  [2.0181e+11, 2.01902e+11, -9999, 9999, 'NaN', 'Ice', 'Eqp'])\n",
    "olcdflvl1.rename(columns=lambda x: x.strip(), inplace=True) #stripping spaces out of names\n",
    "\n",
    "olcdflvl2 = pd.read_csv(waterlevelfiles[2], delimiter=',', comment='#', header=0, \n",
    "                 parse_dates=['Date Time'], index_col= 'Date Time', na_values = \n",
    "                  [2.0181e+11, 2.01902e+11, -9999, 9999, 'NaN', 'Ice', 'Eqp'])\n",
    "olcdflvl2.rename(columns=lambda x: x.strip(), inplace=True) #stripping spaces out of names\n",
    "\n",
    "olcdflvl3 = pd.read_csv(waterlevelfiles[3], delimiter=',', comment='#', header=0, \n",
    "                 parse_dates=['Date Time'], index_col= 'Date Time', na_values = \n",
    "                  [2.0181e+11, 2.01902e+11, -9999, 9999, 'NaN', 'Ice', 'Eqp'])\n",
    "olcdflvl3.rename(columns=lambda x: x.strip(), inplace=True) #stripping spaces out of names\n",
    "\n",
    "olcdflvl4 = pd.read_csv(waterlevelfiles[4], delimiter=',', comment='#', header=0, \n",
    "                 parse_dates=['Date Time'], index_col= 'Date Time', na_values = \n",
    "                  [2.0181e+11, 2.01902e+11, -9999, 9999, 'NaN', 'Ice', 'Eqp'])\n",
    "olcdflvl4.rename(columns=lambda x: x.strip(), inplace=True) #stripping spaces out of names\n",
    "\n",
    "olcdflvl5 = pd.read_csv(waterlevelfiles[5], delimiter=',', comment='#', header=0, \n",
    "                 parse_dates=['Date Time'], index_col= 'Date Time', na_values = \n",
    "                  [2.0181e+11, 2.01902e+11, -9999, 9999, 'NaN', 'Ice', 'Eqp'])\n",
    "olcdflvl5.rename(columns=lambda x: x.strip(), inplace=True) #stripping spaces out of names\n",
    "\n",
    "#Joining into one site dataframe, trimming to the date, renaming columns\n",
    "olcdflvl = pd.concat([olcdflvl0, olcdflvl1, olcdflvl2, olcdflvl3, olcdflvl4, \n",
    "                      olcdflvl5], axis=0, join='outer', ignore_index=False)\n",
    "olcdflvl = olcdflvl[startdate:enddate]\n",
    "olcdflvl.rename(columns = {'Water Level' : 'Olcott'}, inplace = True)\n",
    "\n",
    "##############################################################################  Breaks between sites\n",
    "\n",
    "capedflvl0 = pd.read_csv(waterlevelfiles[6], delimiter=',', comment='#', header=0, \n",
    "                 parse_dates=['Date Time'], index_col= 'Date Time', na_values = \n",
    "                  [2.0181e+11, 2.01902e+11, -9999, 9999, 'NaN', 'Ice', 'Eqp'])\n",
    "capedflvl0.rename(columns=lambda x: x.strip(), inplace=True) #stripping spaces out of names\n",
    "\n",
    "capedflvl1 = pd.read_csv(waterlevelfiles[7], delimiter=',', comment='#', header=0, \n",
    "                 parse_dates=['Date Time'], index_col= 'Date Time', na_values = \n",
    "                  [2.0181e+11, 2.01902e+11, -9999, 9999, 'NaN', 'Ice', 'Eqp'])\n",
    "capedflvl1.rename(columns=lambda x: x.strip(), inplace=True) #stripping spaces out of names\n",
    "\n",
    "capedflvl2 = pd.read_csv(waterlevelfiles[8], delimiter=',', comment='#', header=0, \n",
    "                 parse_dates=['Date Time'], index_col= 'Date Time', na_values = \n",
    "                  [2.0181e+11, 2.01902e+11, -9999, 9999, 'NaN', 'Ice', 'Eqp'])\n",
    "capedflvl2.rename(columns=lambda x: x.strip(), inplace=True) #stripping spaces out of names\n",
    "\n",
    "capedflvl3 = pd.read_csv(waterlevelfiles[9], delimiter=',', comment='#', header=0, \n",
    "                 parse_dates=['Date Time'], index_col= 'Date Time', na_values = \n",
    "                  [2.0181e+11, 2.01902e+11, -9999, 9999, 'NaN', 'Ice', 'Eqp'])\n",
    "capedflvl3.rename(columns=lambda x: x.strip(), inplace=True) #stripping spaces out of names\n",
    "\n",
    "capedflvl4 = pd.read_csv(waterlevelfiles[10], delimiter=',', comment='#', header=0, \n",
    "                 parse_dates=['Date Time'], index_col= 'Date Time', na_values = \n",
    "                  [2.0181e+11, 2.01902e+11, -9999, 9999, 'NaN', 'Ice', 'Eqp'])\n",
    "capedflvl4.rename(columns=lambda x: x.strip(), inplace=True) #stripping spaces out of names\n",
    "\n",
    "capedflvl5 = pd.read_csv(waterlevelfiles[11], delimiter=',', comment='#', header=0, \n",
    "                 parse_dates=['Date Time'], index_col= 'Date Time', na_values = \n",
    "                  [2.0181e+11, 2.01902e+11, -9999, 9999, 'NaN', 'Ice', 'Eqp'])\n",
    "capedflvl5.rename(columns=lambda x: x.strip(), inplace=True) #stripping spaces out of names\n",
    "\n",
    "#Joining into one site dataframe, trimming to the dates, renaming columns\n",
    "capedflvl = pd.concat([capedflvl0, capedflvl1, capedflvl2, capedflvl3, capedflvl4,\n",
    "                       capedflvl5], axis=0, join='outer', ignore_index=False)\n",
    "capedflvl = capedflvl[startdate:enddate]\n",
    "capedflvl.rename(columns = {'Water Level' : 'Cape Vincent'}, inplace = True)\n",
    "\n",
    "##############################################################################  Breaks between sites\n",
    "\n",
    "ozdflvl0 = pd.read_csv(waterlevelfiles[12], delimiter=',', comment='#', header=0, \n",
    "                 parse_dates=['Date Time'], index_col= 'Date Time', na_values = \n",
    "                  [2.0181e+11, 2.01902e+11, -9999, 9999, 'NaN', 'Ice', 'Eqp'])\n",
    "ozdflvl0.rename(columns=lambda x: x.strip(), inplace=True) #stripping spaces out of names\n",
    "\n",
    "ozdflvl1 = pd.read_csv(waterlevelfiles[13], delimiter=',', comment='#', header=0, \n",
    "                 parse_dates=['Date Time'], index_col= 'Date Time', na_values = \n",
    "                  [2.0181e+11, 2.01902e+11, -9999, 9999, 'NaN', 'Ice', 'Eqp'])\n",
    "ozdflvl1.rename(columns=lambda x: x.strip(), inplace=True) #stripping spaces out of names\n",
    "\n",
    "ozdflvl2 = pd.read_csv(waterlevelfiles[14], delimiter=',', comment='#', header=0, \n",
    "                 parse_dates=['Date Time'], index_col= 'Date Time', na_values = \n",
    "                  [2.0181e+11, 2.01902e+11, -9999, 9999, 'NaN', 'Ice', 'Eqp'])\n",
    "ozdflvl2.rename(columns=lambda x: x.strip(), inplace=True) #stripping spaces out of names\n",
    "\n",
    "ozdflvl3 = pd.read_csv(waterlevelfiles[15], delimiter=',', comment='#', header=0, \n",
    "                 parse_dates=['Date Time'], index_col= 'Date Time', na_values = \n",
    "                  [2.0181e+11, 2.01902e+11, -9999, 9999, 'NaN', 'Ice', 'Eqp'])\n",
    "ozdflvl3.rename(columns=lambda x: x.strip(), inplace=True) #stripping spaces out of names\n",
    "\n",
    "ozdflvl4 = pd.read_csv(waterlevelfiles[16], delimiter=',', comment='#', header=0, \n",
    "                 parse_dates=['Date Time'], index_col= 'Date Time', na_values = \n",
    "                  [2.0181e+11, 2.01902e+11, -9999, 9999, 'NaN', 'Ice', 'Eqp'])\n",
    "ozdflvl4.rename(columns=lambda x: x.strip(), inplace=True) #stripping spaces out of names\n",
    "\n",
    "ozdflvl5 = pd.read_csv(waterlevelfiles[17], delimiter=',', comment='#', header=0, \n",
    "                 parse_dates=['Date Time'], index_col= 'Date Time', na_values = \n",
    "                  [2.0181e+11, 2.01902e+11, -9999, 9999, 'NaN', 'Ice', 'Eqp'])\n",
    "ozdflvl5.rename(columns=lambda x: x.strip(), inplace=True) #stripping spaces out of names\n",
    "\n",
    "#Joining into one site dataframe, trimming to the dates, renaming columns\n",
    "ozdflvl = pd.concat([ozdflvl0, ozdflvl1, ozdflvl2, ozdflvl3, ozdflvl4,\n",
    "                       ozdflvl5], axis=0, join='outer', ignore_index=False)\n",
    "ozdflvl = ozdflvl[startdate:enddate]\n",
    "ozdflvl.rename(columns = {'Water Level' : 'Oswego'}, inplace = True)\n",
    "\n",
    "##############################################################################  Breaks between sites\n",
    "\n",
    "rochdflvl0 = pd.read_csv(waterlevelfiles[18], delimiter=',', comment='#', header=0, \n",
    "                 parse_dates=['Date Time'], index_col= 'Date Time', na_values = \n",
    "                  [2.0181e+11, 2.01902e+11, -9999, 9999, 'NaN', 'Ice', 'Eqp'])\n",
    "rochdflvl0.rename(columns=lambda x: x.strip(), inplace=True) #stripping spaces out of names\n",
    "\n",
    "rochdflvl1 = pd.read_csv(waterlevelfiles[19], delimiter=',', comment='#', header=0, \n",
    "                 parse_dates=['Date Time'], index_col= 'Date Time', na_values = \n",
    "                  [2.0181e+11, 2.01902e+11, -9999, 9999, 'NaN', 'Ice', 'Eqp'])\n",
    "rochdflvl1.rename(columns=lambda x: x.strip(), inplace=True) #stripping spaces out of names\n",
    "\n",
    "rochdflvl2 = pd.read_csv(waterlevelfiles[20], delimiter=',', comment='#', header=0, \n",
    "                 parse_dates=['Date Time'], index_col= 'Date Time', na_values = \n",
    "                  [2.0181e+11, 2.01902e+11, -9999, 9999, 'NaN', 'Ice', 'Eqp'])\n",
    "rochdflvl2.rename(columns=lambda x: x.strip(), inplace=True) #stripping spaces out of names\n",
    "\n",
    "rochdflvl3 = pd.read_csv(waterlevelfiles[21], delimiter=',', comment='#', header=0, \n",
    "                 parse_dates=['Date Time'], index_col= 'Date Time', na_values = \n",
    "                  [2.0181e+11, 2.01902e+11, -9999, 9999, 'NaN', 'Ice', 'Eqp'])\n",
    "rochdflvl3.rename(columns=lambda x: x.strip(), inplace=True) #stripping spaces out of names\n",
    "\n",
    "rochdflvl4 = pd.read_csv(waterlevelfiles[22], delimiter=',', comment='#', header=0, \n",
    "                 parse_dates=['Date Time'], index_col= 'Date Time', na_values = \n",
    "                  [2.0181e+11, 2.01902e+11, -9999, 9999, 'NaN', 'Ice', 'Eqp'])\n",
    "rochdflvl4.rename(columns=lambda x: x.strip(), inplace=True) #stripping spaces out of names\n",
    "\n",
    "rochdflvl5 = pd.read_csv(waterlevelfiles[23], delimiter=',', comment='#', header=0, \n",
    "                 parse_dates=['Date Time'], index_col= 'Date Time', na_values = \n",
    "                  [2.0181e+11, 2.01902e+11, -9999, 9999, 'NaN', 'Ice', 'Eqp'])\n",
    "rochdflvl5.rename(columns=lambda x: x.strip(), inplace=True) #stripping spaces out of names\n",
    "\n",
    "#Joining into one site dataframe, trimming to the dates, renaming columns\n",
    "rochdflvl = pd.concat([rochdflvl0, rochdflvl1, rochdflvl2, rochdflvl3, rochdflvl4,\n",
    "                       rochdflvl5], axis=0, join='outer', ignore_index=False)\n",
    "rochdflvl = rochdflvl[startdate:enddate]\n",
    "rochdflvl.rename(columns = {'Water Level' : 'Rochester'}, inplace = True)\n",
    "\n",
    "#Keeping only water level columns which has been named with site names\n",
    "olcdflvl = olcdflvl[['Olcott']]\n",
    "capedflvl = capedflvl[['Cape Vincent']]\n",
    "ozdflvl = ozdflvl[['Oswego']]\n",
    "rochdflvl = rochdflvl[['Rochester']]\n",
    "\n",
    "#resamlping to ensure all days are covered, and linearly interpolating any missing data\n",
    "olcdflvl = olcdflvl.resample('1D').interpolate('linear') #large stretch from mid '99 to mid '00 missing\n",
    "capedflvl = capedflvl.resample('1D').interpolate('linear')\n",
    "ozdflvl = ozdflvl.resample('1D').interpolate('linear')\n",
    "rochdflvl = rochdflvl.resample('1D').interpolate('linear')\n",
    "\n",
    "#Joining into one main dataframe with all waterlevel data\n",
    "waterlevel = pd.concat([olcdflvl, capedflvl, ozdflvl, rochdflvl], axis = 1) \n",
    "\n",
    "#Calculating standard dev\n",
    "stdev = waterlevel.std(axis = 1)\n",
    "\n",
    "#Getting average lake level\n",
    "avgLL = pd.DataFrame()\n",
    "avgLL['avg'] = waterlevel.mean(axis = 1)\n",
    "\n",
    "maximumwldiff = max(stdev) #ft\n",
    "avgwldiff = stdev.mean()\n",
    "maximumwldiffdate = datetime.datetime(2000, 2, 18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccdb557a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Importing Discharge data\n",
    "\n",
    "niagdscg = pd.read_csv(dscgfiles[0], delimiter='\\t', comment='#', header=1, \n",
    "                 parse_dates=['20d'], index_col= '20d', na_values = \n",
    "                  [2.0181e+11, 2.01902e+11, -9999, 9999, 'NaN', 'Ice', 'Eqp'])\n",
    "niagdscg = niagdscg[['14n']]\n",
    "niagdscg.rename(columns={'14n':'Q Niag'}, inplace = True)\n",
    "\n",
    "\n",
    "genndscg = pd.read_csv(dscgfiles[2], delimiter='\\t', comment='#', header=1, \n",
    "                 parse_dates=['20d'], index_col= '20d', na_values = \n",
    "                  [2.0181e+11, 2.01902e+11, -9999, 9999, 'NaN', 'Ice', 'Eqp'])\n",
    "genndscg = genndscg[['14n']]\n",
    "genndscg.rename(columns={'14n':'Q Genn'}, inplace = True)\n",
    "\n",
    "\n",
    "blackdscg = pd.read_csv(dscgfiles[3], delimiter='\\t', comment='#', header=1, \n",
    "                 parse_dates=['20d'], index_col= '20d', na_values = \n",
    "                  [2.0181e+11, 2.01902e+11, -9999, 9999, 'NaN', 'Ice', 'Eqp'])\n",
    "blackdscg = blackdscg[['14n']]\n",
    "blackdscg.rename(columns={'14n':'Q Black'}, inplace = True)\n",
    "\n",
    "\n",
    "ozdscg = pd.read_csv(dscgfiles[4], delimiter='\\t', comment='#', header=1, \n",
    "                 parse_dates=['20d'], index_col= '20d', na_values = \n",
    "                  [2.0181e+11, 2.01902e+11, -9999, 9999, 'NaN', 'Ice', 'Eqp'])\n",
    "ozdscg = ozdscg[['14n']]\n",
    "ozdscg.rename(columns={'14n':'Q Oz'}, inplace = True)\n",
    "\n",
    "\n",
    "lawrencedscg = pd.read_csv(dscgfiles[1], delimiter='\\t', comment='#', header=1, \n",
    "                 parse_dates=['20d'], index_col= '20d', na_values = \n",
    "                  [2.0181e+11, 2.01902e+11, -9999, 9999, 'NaN', 'Ice', 'Eqp'])\n",
    "lawrencedscg = lawrencedscg[['14n']]\n",
    "lawrencedscg['14n'] = lawrencedscg['14n']*86400\n",
    "lawrencedscg.rename(columns={'14n':'Q Out'}, inplace = True)\n",
    "\n",
    "\n",
    "discharge = pd.concat([niagdscg, lawrencedscg, genndscg, blackdscg, ozdscg], axis = 1)\n",
    "\n",
    "discharge['qsum'] = discharge.iloc[:, [0, 2, 3, 4]].sum(axis = 1)\n",
    "discharge['Q In'] = discharge['qsum']*86400 #cubic feet per day\n",
    "qdiff = discharge['Q In'] - discharge['Q Out']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b817af50",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Importing precip data\n",
    "\n",
    "ozprcp = pd.read_csv(prcpfile[0], delimiter=',', comment='#', header=0, \n",
    "                 parse_dates=['DATE'], index_col= 'DATE', na_values = \n",
    "                  [2.0181e+11, 2.01902e+11, -9999, 9999, 'NaN', 'Ice', 'Eqp'])\n",
    "ozprcp = ozprcp[['PRCP']]\n",
    "ozprcp.rename(columns={'PRCP':'Oz P'}, inplace = True)\n",
    "ozprcp = ozprcp.resample('1D').asfreq().fillna(0) #filling NaNs with 0\n",
    "\n",
    "rochprcp = pd.read_csv(prcpfile[1], delimiter=',', comment='#', header=0, \n",
    "                 parse_dates=['DATE'], index_col= 'DATE', na_values = \n",
    "                  [2.0181e+11, 2.01902e+11, -9999, 9999, 'NaN', 'Ice', 'Eqp'])\n",
    "rochprcp = rochprcp[['PRCP']]\n",
    "rochprcp.rename(columns={'PRCP':'Roch P'}, inplace = True)\n",
    "rochprcp = rochprcp.resample('1D').asfreq().fillna(0) #filling NaNs with 0\n",
    "\n",
    "wtprcp = pd.read_csv(prcpfile[2], delimiter=',', comment='#', header=0, \n",
    "                 parse_dates=['DATE'], index_col= 'DATE', na_values = \n",
    "                  [2.0181e+11, 2.01902e+11, -9999, 9999, 'NaN', 'Ice', 'Eqp'])\n",
    "wtprcp = wtprcp[['PRCP']]\n",
    "wtprcp.rename(columns={'PRCP':'WT P'}, inplace = True)\n",
    "wtprcp = wtprcp.resample('1D').asfreq().fillna(0) #filling NaNs with 0\n",
    "\n",
    "precipitation = pd.concat([ozprcp, rochprcp, wtprcp], axis = 1)\n",
    "\n",
    "prcptotal = precipitation.sum(axis = 1)\n",
    "#prcptotal = precipitation['total'].replace({'0':np.nan, 0:np.nan})\n",
    "\n",
    "#llx, lly = np.polyfit(avgLL.index.view('int64')/1e9, avgLL['avg'], 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b216b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Making one complete dataframe with average water level, combined discharge\n",
    "#and total precipitation\n",
    "\n",
    "dfall = pd.concat([avgLL, prcptotal, qdiff], axis = 1)\n",
    "dfall.rename(columns={0:'q'}, inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1abfa3c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "\n",
    "fig, (ax) = plt.subplots()\n",
    "\n",
    "ax.plot(avgLL, color = 'r')\n",
    "ax2 = ax.twinx()\n",
    "ax2.plot(discharge['Q Difference'], linestyle = 'dotted')\n",
    "ax3 = ax.twinx()\n",
    "ax3.plot(precipitation['total'], color = 'k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c82703e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Defining flood events and years\n",
    "\n",
    "#plan 2014 was agreed to and enacted in 2016, previous plan was 1958D which was\n",
    "# in use since 1963 (floods 1973-1998 all plan 1958D)\n",
    "floodyear = pd.DataFrame()\n",
    "floodyear['start'] = ['1952-01-01', '1973-01-01', '1976-01-01','1983-01-01', \n",
    "                      '1998-01-01','2017-01-01', '2019-01-01',]\n",
    "floodyear['end'] = ['1952-12-31', '1973-12-31', '1976-12-31', '1983-12-31', \n",
    "                    '1998-12-31','2017-12-31', '2019-12-31']\n",
    "\n",
    "floodyear['start'] = pd.to_datetime(floodyear['start'])\n",
    "floodyear['end'] = pd.to_datetime(floodyear['end'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09726937",
   "metadata": {},
   "outputs": [],
   "source": [
    "def timeplot(df, startdates, enddates):\n",
    "\n",
    "    fig, (ax1, ax2, ax3) = plt.subplots(3, 1, sharex = True)\n",
    "    \n",
    "    #plotting soil moistures 1a\n",
    "    ax1.plot(df['avg'], label = 'Lake Height')\n",
    "    ax1.twinx().plot(df['q'], color = 'r')\n",
    "    \n",
    "    #plotting precip 1b\n",
    "    ax2.plot(df['avg'], label = 'Lake Height')\n",
    "    ax2.twinx().plot(df['total'], color = 'k', label = 'Precip')\n",
    "    \n",
    "    #plotting trapz 1c\n",
    "    ax3.plot(df['avg'], label = 'Lake Height')\n",
    "    ax3.twinx().plot(df['q'], color = 'r', label = 'Discharge Difference')\n",
    "    ax3.twinx().plot(df['total'], color = 'k', label = 'Precip')\n",
    "    \n",
    "    ax3.legend(bbox_to_anchor=(1,1), loc='best')\n",
    "    \n",
    "    \n",
    "timeplot(dfall, startdate, enddate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b49194",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, v in enumerate(floodyear['start']):\n",
    "    finaldate = floodyear.iloc[i,1]\n",
    "    loop = dfall[v:finaldate]\n",
    "    timeplot(loop, v, finaldate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea16b1e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
